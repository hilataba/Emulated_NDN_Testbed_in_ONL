NDN Data Collection Framework README
------------------------------------

## QUICK START

To build this directory:
        ./waf configure
        ./waf

Then run ./startAll.sh [prefix]
Example: > ./startAll.sh /ndn/edu

## CONTENTS

1.] Configuration Files
2.] Steps to run Data Collection
3.] Application documentation
4.] Examples
5.] ICN Demo

## CONFIGURATION FILES

For any ONL topology, the following files must be configured:

-- hosts :	contains router/host pairs in the form:
		[router alias]:[host]:[router name]
-- routers :	contains neighboring routers in the form:
		[router name]:[site name]:[host alias]:[router ip]:[{neighbor router name}: for each neighbor]
-- linksList :	contains one-to-many list of links between nodes and their neighbors in the form:
		<link ID> <link prefix> <link IP>
-- NLSR_CONF :	each site must have a unique NLSR.conf file (ex: wustl.conf). Use setup_conf.py
		in NLSR_CONF directory to create these

## STEPS TO RUN DATA COLLECTION ON ONL
(NOTE: these instruction only work on WUSTL's ONL)

First step is always configure files from CONFIGURATION FILES above.

-- Standard NFD Face stat collection:
onlusr> ./startAll [prefix]

-- To use scripts:
1.]	onlusr> ./startNfd.sh
2.]	onlusr> ./startNlsr.sh
3.]	onlusr> ./configAll.sh [prefix]
4.]	onlusr> ./startDataCollectionScripts.sh [prefix]
5.]	onlusr> ssh [any router node]
6.]	router_node> ./build/nfdstat_s -f [linksList] -n [number_of_links] -x -k [scriptList]

'scriptList' contains a list of scripts to be run on each client node. For example:
	getNfdPid.sh
	getNfdLogSize.sh
	foo.py
	bar.py

-- To run a single script on a single node:
On onlusr, do steps 1-5 as above.  Once ssh'd in to a router:
router_node> ./build/nfdstat_s -x -i [target node] -y [script name]

## Application documentation

SERVER: nfdstat_s
 Usage:
 ./build/nfdstat_s[-h] -f link_file -n number_of_linkids [-k script_file] [-s map_addr] [-t poll_period] [-r timeout_period] [-d debug_mode] [-l store locally] [-i specify target] [-specify script] [-x suppress collector]

 Poll the status of remote clients and/or run custom data collection scripts on nodes.

  -h 			- print this message and exit
  -f file_name 		- link_file is name of the file containing pairs associated with linkid.
 			   valid line format: <linkId> <interestPrefix> <LinkIP>
 			   example: 1 /ndn/edu/arizona 192.168.1.3
  -n number_of_linkids 	- supplied by the linkfile
  -k script_file 	- script_file is name of file containing list of scripts to run.
  -s map_addr 		- addr added to curl command for ndn map
  -t poll_period 	- in seconds, default is 1 second
  -r timeout_period 	- in milliseconds, default is 500 ms
  -d debug mode 	- 1 set debug on, 0 set debug off (default)
  -l store locally 	- store collected data in log file named '<data/time>.log'
  -i specify target 	- send an interest to a single node (must be used with -y option)
  -y specify script 	- run a single script on target node (must be used with -i option)
  -x suppress Collector - suppresses basic status collection for links in linkfile (faceID, linkIP,
			  Tx, Rx and timestamp for each link)

CLIENT: nfdstat_c
 Usage:
 ./build/nfdstat_c[-h] -p interest_filter [-d debug_mode]

 Pull local nfd performace and send it as a response to an interest from a remote server, or listen
 and reply to script interests.

 	-h - print this message and exit
 	-p - prefix (of this host) to register as the interest's filter
 	-d - sets the debug mode, 1 - debug on, 0 - debug off (default)
 	-b - set size of buffer for storing data collected, useful for
 		  scripts collecting large data sets. Default is 1024 bytes

## EXAMPLES

  onlusr>  ./startDataCollectionScripts.sh /ndn

  # scriptslist_2 contains only ipPing.py
  wu_host> ./build/nfdstat_s -x -f linksList -n 132 -k scriptslist_2

## ICN DEMO


